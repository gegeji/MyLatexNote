\chapter{以$k$-Means算法为例的优化问题}
    
\begin{problem}
    \label{Problem:ClusteringCenter}
    假设$N$个样本向量$ x_{1}, \ldots, x_{N} \in \mathbb{R}^{n} $，需要找到中心向量$z$满足

    $$ \min _{z \in \mathbf{R}^{n}} \sum_{i=1}^{N}\left\|x_{i}-z\right\|_{2}^{2} $$
\end{problem}

\begin{definition}[高阶无穷小记号 $o$]
    设 $ x, y $ 是同一变化过程中的无穷小，即 $ x \rightarrow 0, y \rightarrow 0 $, 如果它们极限
$$
\lim \frac{y}{x}=0
$$

则称 $ y $ 是 $ x $ 的高阶无穷小，记作 $ y=o(x) $.
\end{definition}

\begin{corollary}
    $$ \lim \frac{y}{C x}=\frac{1}{C} \lim \frac{y}{x}=0 $$

    也即则称 $ y $ 是 $ C x $ 的高阶无穷小，记作 $ y=o(C x) $ 。
\end{corollary}

\begin{proposition}[优化求解的必要条件]
    假设函数$f$在$\hat{x}$可微，则有

    $$ \hat{x}=\arg \min _{x \in \mathbb{R}^{n}} f(x) \Rightarrow \nabla f(\hat{x})=0 $$
\end{proposition}

\begin{proof}
    假设函数$f$在$\hat{x}$一阶泰勒展开, 有

    $$ f(x)=f(\hat{x})+\langle\nabla f(\hat{x}), x-\hat{x}\rangle+o\left(\|x-\hat{x}\|_{2}\right) $$

    假设$ \delta f(\hat{x}) \neq 0 $, 则令 $ \tilde{x}=\hat{x}-t \nabla f(\hat{x}), t>0 $,可得

    $$ f(\tilde{x})=f(\hat{x})-t\|\nabla f(\hat{x})\|_{2}^{2}+o\left(t\|\nabla f(\hat{x})\|_{2}\right) $$

    当 $ t \rightarrow 0 $ 则$ t\|\nabla f(\hat{x})\|_{2} \rightarrow 0 $， 高阶无穷小$ {o }^{\prime}\left(t\|\nabla f(\hat{x})\|_{2}\right) \rightarrow 0 $

    当$t$足够小时，存在$ t\|\nabla f(\hat{x})\|_{2} \geq o\left(t\|\nabla f(\hat{x})\|_{2}\right) $，即

    $$ -t\|\nabla f(\hat{x})\|_{2}^{2}+o\left(t\|\nabla f(\hat{x})\|_{2}\right) \leq 0 $$

    $$ f(\tilde{x})=f(\hat{x})-t\|\nabla f(\hat{x})\|_{2}^{2}+o\left(t\|\nabla f(\hat{x})\|_{2}\right) \leq f(\hat{x}) $$

    与 $ \hat{x}=\arg \min _{\mathbf{R}^{n}} f(x) $ 矛盾。

    $ \nabla f(\widehat{x})=0 $, 是最优问题解的必要条件。通常 $ \nabla f(\hat{x})=0 \not \Leftrightarrow \hat{x}=\arg \min _{\mathbf{R}^{n}} f(x) $。
\end{proof}

\begin{example}
    $$ f(x)=-x^{2}, \quad x \in \mathbb{R}, \hat{x}=\operatorname{argmin}_{\mathbb{R}} f(x) $$

    $ \nabla f(\hat{x})=0 $, 则有 $ -2 \hat{x}=0 $, 即 $ \hat{x}=0 $

    $$ f(\hat{x})=0 \geq f(x), \quad x \in \mathbf{R} $$


    (最大值!)
\end{example}

\section{Convex Set}

\begin{definition}[凸集]
    $ \forall x, y \in \Omega, \alpha \in \mathbb{R}, 0 \leq \alpha \leq 1 $有

    $$ \alpha x+(1-\alpha) y \in \Omega $$

    则定义域$ \Omega \in \mathbb{R}^{n} $称为凸的(Convex)集合

    （域内两点连线之间都属于这个域）
\end{definition}

\begin{definition}[凸函数]
    设函数 $ f(x) $ 定义于称为\textit{凸的定义域} $ \Omega \in \mathbb{R}^{n} $满足

    $$ f(\alpha x+(1-\alpha) y) \leq \alpha f(x)+(1-\alpha) f(y), \forall x, y \in \Omega, \alpha \in \mathbf{R}, 0 \leq \alpha \leq 1 $$

    称其为凸函数。
\end{definition}

% todo 图片

\begin{example}
    \label{Example:SquareIsConvex}
    $$ f(x)=x^{2}, x \in \mathbf{R} $$

    $$ \begin{aligned} f(\alpha x+(1-\alpha) y) &=(\alpha x+(1-\alpha) y)^{2} 
    \\ &=\alpha^{2} x^{2}+2 \alpha(1-\alpha) x y+(1-\alpha)^{2} y^{2} 
    \\ &=\alpha x^{2}+(1-\alpha) y^{2}+\left(\alpha^{2}-\alpha\right) x^{2}+\left(\alpha^{2}-\alpha\right) y^{2}+2 \alpha(1-\alpha) x y 
    \\ &=\alpha x^{2}+(1-\alpha) y^{2}-\alpha(1-\alpha)(x-y)^{2}
    \\ &\leq \alpha x^{2}+(1-\alpha) y^{2}=\alpha f(x)+(1-\alpha) f(y)
    \end{aligned} $$
\end{example}

\begin{example}
    \label{Example:NormIsConvex}
    $ f(x)=\|x\| $, 其中 $ \| $ • $ \| $ 表示 $ \mathbb{R}^{n} $ 上的向量范数, $ x \in \mathbb{R}^{n} $.
\end{example}

\begin{proof}
    \label{Example:L2NormIsConvex}
    $$ \|\alpha x+(1-\alpha) y\| \leq\|\alpha x\|+\|(1-\alpha) y\|=|\alpha|\|x\|+|1-\alpha|\|y\| $$
\end{proof}

\begin{example}
    $$ f(x)=\|x\|_{2}^{2}, x \in \mathbb{R}^{n} $$
\end{example}

\begin{theorem}[可微函数$f$是凸函数的充要条件]
    \label{Theorem:ConvexDiffential}
    $$ f(y) \geq f(x)+\langle\nabla f(x), y-x\rangle, \quad \forall x, y $$
\end{theorem}

\begin{proof}
    首先，证明一维情况 $ f: \mathbb{R} \rightarrow \mathbb{R}, \alpha \in[0,1] $.

    $ \Rightarrow  $ 充分条件: $ f(\alpha x+(1-\alpha) y)=f(x+(1-\alpha)(y-x)) \leq \alpha f(x)+(1-\alpha) f(y) $,有

    $$ f(y) \geq f(x)+\frac{f(x+(1-\alpha)(y-x))-f(x)}{(1-\alpha)(y-x)}(y-x) $$

    令 $ \alpha \rightarrow 1^- $, 则有 $ f(y) \geq f(x)+f^{\prime}(x)(y-x) $.

    $ \Leftarrow  $ 必要条件：令 $ y \neq x, z=\alpha x+(1-\alpha) y$则有

    $$  f(x) \geq f(z)+f^{\prime}(z)(x-z), f(y) \geq f(z)+f^{\prime}(z)(y-z)  $$

    可得 
    $$\begin{aligned}
        \alpha f(x)+(1-\alpha) f(y) &\geq f(z)+\alpha f^{\prime}(z)(x-z)+(1-\alpha) f^{\prime}(z)(y-z) \\
        &=f(z)+f^{\prime}(z)(\alpha x+(1-\alpha) y-z) \\
        &=f(z)
    \end{aligned}
    $$

    证明 $ n $ 维情况 $ f: \mathbb{R}^{n} \rightarrow \mathbb{R} $.

    $ \Rightarrow $ 充分条件：令 $ g(t)=f(t x+(1-t) y), t \in \mathbb{R} $, 则 $ g^{\prime}(t)=\langle\nabla f(t x+(1-t) y), x-y\rangle $ 由于 $ f $ 是凸函数, 证明 $ g(t) $ 也是凸函数；并可得 $ g(0) \geq g(1)+g^{\prime}(1)(-1) $, 得证.

    $ \Leftarrow $ 必要条件：与一维类似。
\end{proof}

\begin{theorem}
    如果可微函数$f$是凸函数，则有

    $$ \hat{x}=\arg \min _{x \in \mathbb{R}^{n}} f(x) \Leftrightarrow \nabla f(\hat{x})=0 $$
\end{theorem}

\begin{proof}
    已证 $ \hat{x}=\arg \min _{x \in \mathbb{R}^{n}} f(x) \Rightarrow $ 可得 $ \nabla f(\hat{x})=0 $

    只需证 $ \nabla f(\hat{x})=0 \Rightarrow \hat{x}=\arg \min _{x \in \mathbb{R}^{n}} f(x) $.

    由于函数 $ f $ 是可微凸的, 则有 $ \forall x \in \mathbb{R}^{n} $,
$$
\begin{aligned}
f(x) & \geq f(\hat{x})+\langle\nabla f(\hat{x}), x-\hat{x}\rangle \\
& \geq f(\hat{x})+\langle 0, x-\hat{x}\rangle \geq f(\hat{x})
\end{aligned}
$$

可得 $ f(x) \geq f(\hat{x}), \hat{x}=\arg \min _{x \in \mathbb{R}^{n}} f(x) $.
\end{proof}

\section{向量偏导}

\begin{definition}[向量对向量的导数]
    \label{Definition:VectorVectorDerivative}
    $$ x=\left[\begin{array}{c}x_{1} \\ \vdots \\ x_{n}\end{array}\right], z=\left[\begin{array}{c}z_{1} \\ \vdots \\ z_{n}\end{array}\right] $$

    $$ \nabla f(z)=\left[\begin{array}{c}\frac{\partial f(z)}{\partial z_{1}} \\ \vdots \\ \frac{\partial f(z)}{\partial z_{n}}\end{array}\right] $$
\end{definition}

\begin{example}
    $$ f(z)=x^{T} z+z^{T} z=\sum_{i=1}^{n}\left\{x_{i} z_{i}+z_{i}^{2}\right\} $$

    $$ \nabla f(z)=\left[\begin{array}{c}\frac{\partial f(z)}{\partial z_{1}} \\ \vdots \\ \frac{\partial f(z)}{\partial z_{n}}\end{array}\right]=\left[\begin{array}{c}x_{1}+2 z_{1} \\ \vdots \\ x_{n}+2 z_{n}\end{array}\right]=x+2 z $$
\end{example}

% todo reference
问题\ref{Problem:ClusteringCenter}中已知目标函数是凸函数。（见\ref{Example:SquareIsConvex}, \ref{Example:NormIsConvex}, \ref{Example:L2NormIsConvex}）

则可以求解

$$ f(z)=\sum_{i=1}^{N}\left\|x_{i}-z\right\|_{2}^{2}=\sum_{i=1}^{N}\left\langle x_{i}-z, x_{i}-z\right\rangle=\sum_{i=1}^{N}\left\{x_{i}^{T} x_{i}-2 x_{i}^{T} z+z_{i}^{T} z\right\} $$

利用等价条件\ref{Theorem:ConvexDiffential}

$$ \nabla f(z)=\sum_{i=1}^{N}\left\{-2 x_{i}+2 z\right\}=0 $$ (求导 \ref{Definition:VectorVectorDerivative})

$$ z=\frac{1}{N} \sum_{i=1}^{N} x_{i} $$

\section{标量优化问题的例子：投影问题}

\begin{figure}[htbp]
    \begin{center}
        

\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
%uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300

%Straight Lines [id:da6245666898381868] 
\draw    (101,120) -- (179.63,53.38) ;
\draw [shift={(181.15,52.09)}, rotate = 499.72] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da028563208619883484] 
\draw    (101,120) -- (129.15,119.79) -- (224.15,119.1) ;
\draw [shift={(226.15,119.09)}, rotate = 539.5799999999999] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da8014408982517005] 
\draw  [dash pattern={on 0.84pt off 2.51pt}]  (181.15,62.09) -- (181.15,114.09) ;
%Straight Lines [id:da3438902495351597] 
\draw [color={rgb, 255:red, 236; green, 29; blue, 29 }  ,draw opacity=1 ][fill={rgb, 255:red, 223; green, 36; blue, 36 }  ,fill opacity=1 ][line width=2.25]    (101,120) -- (172.65,119.48) ;
\draw [shift={(177.65,119.44)}, rotate = 539.5799999999999] [fill={rgb, 255:red, 236; green, 29; blue, 29 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (14.29,-6.86) -- (0,0) -- (14.29,6.86) -- cycle    ;

% Text Node
\draw (228,110.4) node [anchor=north west][inner sep=0.75pt]    {$a$};
% Text Node
\draw (188,39.4) node [anchor=north west][inner sep=0.75pt]    {$b$};
% Text Node
\draw (139,123.4) node [anchor=north west][inner sep=0.75pt]    {$\hat{t} a$};
% Text Node
\draw (190,76.4) node [anchor=north west][inner sep=0.75pt]    {$b-\hat{t} a$};


\end{tikzpicture}

    \end{center}


\end{figure}

\begin{problem}
    假设$ a, b \in \mathbb{R}^{n}, a \neq 0, t \in \mathbb{R} $，当$t$ 多大时，$ta$到$b$之间的距离最小

    $$ \hat{t}=\min _{t}\|t a-b\|_{2}^{2} $$

    $$ f(t)=\|t a-b\|_{2}^{2}=\langle t a-b, t a-b\rangle=t^{2} a^{T} a-2 t a^{T} b+b^{T} b $$

    $$ \nabla f(t)=2 t a^{T} a-2 a^{T} b=0 $$

    $$ \hat{t}=\frac{a^{T} b}{a^{T} a}=\frac{a^{T} b}{\|a\|_{2}^{2}} $$
\end{problem}

\section{Clustering}

将物理或抽象对象的集合分成由类似特征组成的多个类的过程称为\textit{聚类(clustering)}.



目标：分成$k$个集合，尽量使得同一个集合中的向量彼此接近。

\begin{notation}
    给定N个n维向量 $ x_{1}, \ldots, x_{N} \in \mathbb{R}^{n} $

    \begin{itemize}
        \item 标签 $ c_{i} \in\{1,2, \cdots, k\} $ 表示向量 $ x_{i} $ 所属类别, 例如 $ c_{i}=2 $ 表示 $ x_{i} $ 属于第2类。
        \item 对于 $ j=1, \ldots, k, \quad G_{j}=\left\{i: c_{i}=j\right\} $ 表示属于第j类的向量 $ x_{i} $ 的下标集合。
        \item 向量 $ z_{j}, j=1, \ldots, k $, 表示同属于 $ j $ 类的向量 $ x_{i}, i \in G_{j} $ 的聚类中心。
    \end{itemize}
\end{notation}

聚类目标是找到向量 $ x_{i} $ 的“标签 $ c_{i} $ ”和“聚类中心 $ z_{j} $ ”

\begin{problem}
    $$ \min _{z_{j}} \sum_{i \in G_{j}}\left\|x_{i}-z_{j}\right\|_{2}^{2}, j=1, \cdots, k $$

    $$ c_{i}=\underset{j=\{1, \cdots, k\}}{\operatorname{argmin}}\left\|x_{i}-z_{j}\right\|_{2}^{2}, i=1,2, \ldots, N $$

    
\end{problem}

$k$-means算法是将 $ \mathrm{N} $ 向量 $ x_{i} \in \mathbb{R}^{n} $ 划分成$k$类的迭代聚类算法。

\begin{algorithm}
    \caption{$k$-means Algorithm}
    在 $ \mathrm{N} $ 个点中随机选取$k$个点，分别作为聚类中心 $ z_{j} $\;
    更新聚类标签 $ c_{i} $ : 计算每个点 $ x_{i} $ 到k个聚类中心 $ z_{j} $ 的距离, 并将其分配到最近的聚类中心 $ z_{j} $ 所在的聚类中 $ c_{i}=j $\;
    更新聚类中心 $ z_{j} $ ：重新计算每个聚类现在的质心，并以其作作为新的聚类中心, 根据更新标签 $ c_{i} $, 更新属于第j类下标集合$ G_{j}=\left\{i: c_{i}=j\right\} $, 重新计算 $ c_{i} $ 类的聚类中心 $ z_{j} $\;
    重复步骤2、3，直到所有聚类中心不再变化
\end{algorithm}

\begin{proof}
    更新聚类标签 $ c_{i} $:

    $$ \left\|x_{i}-z_{j}\right\|_{2}^{2}=\operatorname{argmin}\left\{\left\|x_{i}-z_{1}\right\|_{2}^{2},\left\|x_{i}-z_{2}\right\|_{2}^{2}, \cdots,\left\|x_{i}-z_{k}\right\|_{2}^{2}\right\} $$

    更新聚类中心 $ z_{j} $：

    $$ \nabla f_{j}\left(z_{j}\right)=\sum_{i \in G_{j}} 2\left(x_{i}-z_{j}\right)=0 $$
$$ z_{j}=\frac{1}{\left|G_{j}\right|} \sum_{i \in G_{j}} x_{i} $$

$ \left|G_{j}\right| $ 表示集合 $ G_{j} $ 中元素的数目。
\end{proof}

在每一次迭代中目标函数$J$都会下降, 直到聚类中心 $ z_{1}, \cdots, z_{k} $ 和 划分聚类标签集合 $ G_{1}, \cdots, G_{k} $ 不再变化。

但是k-means算法依赖于初始随机生成的聚类中心，只可得到目标函数$J$的局部局部最优。

解决方案：使用不同的(随机的)初始聚类中心运行k-means算法若干次，取目标函数$J$值最小的一次作为最终的聚类结果。

