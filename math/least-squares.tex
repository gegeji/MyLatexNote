\chapter{Least Squares}

\section{An Example: Measurement Problem}

\begin{problem}
    已知测量量路段长度： $ A D=89, A C=67, B D=53, A B=35, C D=20 $ $ , x_{1}, x_{2} $ 和 $ x_{3} $ 的长度是多少?
\end{problem}

\begin{FigureCenter}{Measurement Problem}
    \input{tikz_images/measurement-problem.tex}
\end{FigureCenter}

由 $ x_{1}, x_{2} $ 和 $ x_{3} $ 的关系可得方程组:
\begin{equation}
\left\{\begin{array}{r}
x_{1}+x_{2}+x_{3}=89 \\
x_{1}+x_{2}=67 \\
x_{2}+x_{3}=53 \\
x_{1}=35 \\
x_{3}=20
\end{array} \Leftrightarrow A x=b, A=\left[\begin{array}{lll}
1 & 1 & 1 \\
1 & 1 & 0 \\
0 & 1 & 1 \\
1 & 0 & 0 \\
0 & 0 & 1
\end{array}\right], b=\left[\begin{array}{l}
89 \\
67 \\
53 \\
35 \\
20
\end{array}\right]\right.
\end{equation}

取后三个式子求解方程组，回代前两个式子

\begin{equation}\displaystyle  \begin{array}{{>{\displaystyle}l}}
\left\{\begin{array}{ r }
x_{2} +x_{3} =53\\
x_{1} =35\\
x_{3} =20
\end{array} \Rightarrow x_{1} =35,x_{2} =33,x_{3} =20.\right. \\
\left\{\begin{array}{ r }
x_{1} +x_{2} +x_{3} =88\neq 89\\
x_{1} +x_{2} =68\neq 67
\end{array}\right. 
\end{array}\end{equation}
     

由于测量存在误差，方程组之间相互矛盾，该超定方程组无解。

\section{最小二乘问题}

\begin{problem}[最小二乘问题]
    寻找该方程组的近似解，并尽可能逼近方程组的目标$b$, 即残差向量 $ r=A x-b $ 某种度量下尽可能小

    \begin{equation} \min _{x}\|A x-b\|_{2}^{2}=\|r\|_{2}^{2} \quad (\ell_2范数度量残差) \end{equation}
\end{problem}


使用$\ell_1$、$\ell_\infty$等也可以度量误差，但是函数在零点处不光滑，不能求导。

\begin{problem}[求解最小二乘解]
    给定 $ {A} \in \mathfrak{R}^{m \times n}, {b} \in \mathfrak{R}^{m} $, 求解 $ x \in \mathfrak{R}^{n} $ 让目标函数最小

\begin{equation} \min _{x}\|A x-b\|_{2}^{2}=\min _{x} \sum_{i=1}^{m}\left(\sum_{j=1}^{n} A_{i j} x_{j}-b_{i}\right)^{2} \end{equation}
\end{problem}

\begin{notation}[最小二乘法的解]
    记最小二乘法的解为 $ \hat{x} $

    \begin{equation}
    \hat{x}=\arg \underset{x}{\min}\|A x-b\|_{2}^{2}=\arg \underset{x}{\min} \sum_{i=1}^{m}\left(\sum_{j=1}^{n} A_{i j} x_{j}-b_{i}\right)^{2}
    \end{equation}
\end{notation}

\begin{example}
    \begin{equation} f(x)=\|A x-b\|_{2}^{2}, {A}=\left[\begin{array}{cc}2 & 0 \\ -1 & 1 \\ 0 & 2\end{array}\right], b=\left[\begin{array}{c}1 \\ 0 \\ -1\end{array}\right] \end{equation}

    求解\begin{equation}\hat{x} = \arg \underset{x}{\min} \|A x-b\|_{2}^{2}\end{equation}

    解：
    \begin{equation} f(x)=\|A x-b\|_{2}^{2}=\left(2 x_{1}-1\right)^{2}+\left(-x_{1}+x_{2}\right)^{2}+\left(2 x_{2}+1\right)^{2} \end{equation}

    \begin{equation} \frac{\partial f}{\partial x_{1}}=10 x_{1}-2 x_{2}-4 , \frac{\partial f}{\partial x_{2}}=-2 x_{1}+10 x_{2}+4 \end{equation}

    \begin{equation} \nabla f(x)=\left[\begin{array}{l}\dfrac{\partial f}{\partial x_{1}} \\ \dfrac{\partial f}{\partial x_{2}}\end{array}\right]=0 \Rightarrow \hat{x}=\left(\frac{1}{3},-\frac{1}{3}\right)^{T} \end{equation}
\end{example}


\begin{theorem}
    设最小二乘法的解为 $ \hat{x} $ ,满足:
    \begin{equation}
    \|A \hat{x}-b\|_{2}^{2} \leq\|A x-b\|_{2}^{2}, \forall x \in \mathfrak{R}^{n}
    \end{equation}

    当残差 $ \hat{r}=A \hat{x}-b=0 $ 时，则 $ \hat{x} $ 是线性方程组 $ A x=b $ 的解; 否则其为误差最小平方和意义下方程组的近似解。
\end{theorem}



\section{求解最小二乘法}

给定 $ A \in \mathfrak{R}^{m \times n}, b \in \mathfrak{R}^{m}, x \in \mathfrak{R}^{n} $ 目标函数：
\begin{equation}
f(x)=\|A x-b\|_{2}^{2}=\sum_{i=1}^{m}\left(\sum_{j=1}^{n} A_{i j} x_{j}-b_{i}\right)^{2}
\end{equation}

为使目标函数最小，求最优解 $ \hat{x}：\hat{x}=\arg \underset{x}{\min} f(x) $

\begin{theorem}
    可微函数 $ f(x) $ 的最优解 $ \hat{x} $ 满足条件：梯度 $ \nabla f(\hat{x})=\mathbf{0} $ , 即：
\begin{equation}
\nabla f(\hat{x})=\left[\begin{array}{c}
\dfrac{\partial f}{\partial x_{1}}(\hat{x}) \\
\vdots \\
\dfrac{\partial f}{\partial x_{n}}(\hat{x})
\end{array}\right]=2 A^{T}(A \hat{x}-b)=0
\end{equation}
\end{theorem}

利用上面这个定理，可以推导出正规方程和最小二乘解。

\begin{theorem}[正规方程与最小二乘解]
    \begin{equation} A^{T} A x=A^{T} b \end{equation}

    $A$的列向量\textbf{线性无关}时，则 $ \hat{x}=\left(A^{T} A\right)^{-1} A^{T} b $. 
\end{theorem}

\begin{proof}
    设函数 $ g_{i}(x)=\sum_{j=1}^{n} A_{i j} x_{j}-b_{i} $ ,则有

    
        \begin{equation}g_{i}( x) =\sum\limits _{j=1}^{n} A_{ij} x_{j} -b_{i} \Rightarrow \left(\begin{array}{ c c c c c }
        A_{1,1} & \cdots  & A_{1,k} & \cdots  & A_{1,n}\\
        \vdots  &  & \vdots  &  & \vdots \\
        \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{A}\textcolor[rgb]{0.72,0.33,0.31}{_{j,1}}} & \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{\cdots }} & \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{A}\textcolor[rgb]{0.72,0.33,0.31}{_{j,k}}} & \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{\cdots }} & \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{A}\textcolor[rgb]{0.72,0.33,0.31}{_{j,n}}}\\
        \vdots  &  & \vdots  &  & \vdots \\
        A_{m,1} & \cdots  & A_{m,k} & \cdots  & A_{m,n}
        \end{array}\right)\left(\begin{array}{ c }
        \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{x}\textcolor[rgb]{0.72,0.33,0.31}{_{1}}}\\
        \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{\vdots }}\\
        \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{x}\textcolor[rgb]{0.72,0.33,0.31}{_{j}}}\\
        \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{\vdots }}\\
        \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{x}\textcolor[rgb]{0.72,0.33,0.31}{_{n}}}
        \end{array}\right) -\left(\begin{array}{ c }
        \textcolor[rgb]{0,0,0}{b_{1}}\\
        \textcolor[rgb]{0,0,0}{\vdots }\\
        \textcolor[rgb]{0.72,0.33,0.31}{b\boldsymbol{_{j}}}\\
        \textcolor[rgb]{0,0,0}{\vdots }\\
        \textcolor[rgb]{0,0,0}{b_{n}}
        \end{array}\right)\end{equation}
    
    所以
    \begin{equation}\begin{aligned} 
        f(x)&=\|A x-b\|_{2}^{2}
        &=\sum_{i=1}^{m}\left(\sum_{j=1}^{n} A_{i j} x_{j}-b_{i}\right)^{2}
        &=\sum_{i=1}^{m}\left(g_{i}(x)\right)^{2} 
    \end{aligned}\end{equation}

    函数 $ f(x) $ 对变量 $ x_{k} $ 偏导为
    
    \begin{equation} \frac{\partial f(x)}{\partial x_{k}}=\sum_{i=1}^{m}\left(\left(2 g_{i}(x)\right)\left(\frac{\partial g_{i}(x)}{\partial x_{k}}\right)\right) \end{equation}


    又因为
    \begin{equation} \frac{\partial g_{i}(x)}{\partial x_{k}}=A_{i k} \end{equation}


    所以
    \begin{equation} \begin{aligned} 
        \frac{\partial f}{\partial x_{k}}(x) 
        &=\sum_{i=1}^{m} 2\left(g_{i}(x)\right)\left(A_{i k}\right) \\
        &=2 \sum_{i=1}^{m}\left(\left(\sum_{j=1}^{n} A_{i j} x_{j}-b_{i}\right)\left(A_{i k}\right)\right) 
        \\ &=2 \sum_{i=1}^{m}\left(\left(\sum_{j=1}^{n} A_{i j} x_{j}\right)\left(A_{i k}\right)\right)-2 \sum_{i=1}^{m}\left(\left(b_{i}\right)\left(A_{i k}\right)\right) \end{aligned} \end{equation}

    注意有
        

    \begin{equation}\sum\limits _{j=1}^{n} A_{ij} x_{j} \Rightarrow 
    \left(\begin{array}{ c c c c c }
    A_{1,1} & \cdots  & A_{1,k} & \cdots  & A_{1,n}\\
    \vdots  &  & \vdots  &  & \vdots \\
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{A}\textcolor[rgb]{0.72,0.33,0.31}{_{i,1}}} & \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{\cdots }} & \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{A}\textcolor[rgb]{0.72,0.33,0.31}{_{i,k}}} & \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{\cdots }} & \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{A}\textcolor[rgb]{0.72,0.33,0.31}{_{i,n}}}\\
    \vdots  &  & \vdots  &  & \vdots \\
    A_{m,1} & \cdots  & A_{m,k} & \cdots  & A_{m,n}
    \end{array}\right)\left(\begin{array}{ c }
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{x}\textcolor[rgb]{0.72,0.33,0.31}{_{1}}}\\
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{\vdots }}\\
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{x}\textcolor[rgb]{0.72,0.33,0.31}{_{i}}}\\
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{\vdots }}\\
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{x}\textcolor[rgb]{0.72,0.33,0.31}{_{n}}}
    \end{array}\right) =\left(\begin{array}{ c }
    Result_{1}\\
    \vdots \\
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{Result}\textcolor[rgb]{0.72,0.33,0.31}{_{i}}}\\
    \vdots \\
    Result_{m}
    \end{array}\right) =Ax\end{equation}

    \begin{remark}
        在此处$i$是自由变量。
    \end{remark}

    \begin{equation}\displaystyle \sum _{i=1}^{m}\left(\underbrace{\left(\sum _{j=1}^{n} A_{ij} x_{j}\right)}_{Result}( A_{ik})\right) =\begin{array}{ c }
    A_{1,\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}} \times Result_{1}\\
    +\\
    \vdots \\
    +\\
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{A_{i,\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}} \times Result}\textcolor[rgb]{0.72,0.33,0.31}{_{i}}}\\
    +\\
    \vdots \\
    +\\
    A\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{_{\textcolor[rgb]{0,0,0}{m,} k}}} \times Result_{m}
    \end{array} =\left(\begin{array}{ c }
    A_{1,\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}}\\
    \vdots \\
    A_{i,\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}}\\
    \vdots \\
    A_{m,\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}}
    \end{array}\right)^{T} Ax=a_{\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}}^{T} Ax\end{equation}
        
    类似地，有 
    
    \begin{equation}\displaystyle \sum _{i=1}^{m}(( b_{i})( A_{ik})) =\begin{array}{ c }
    A_{1,\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}} \times b_{1}\\
    +\\
    \vdots \\
    +\\
    \boldsymbol{\textcolor[rgb]{0.72,0.33,0.31}{A}\textcolor[rgb]{0.72,0.33,0.31}{_{i,\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}}}\textcolor[rgb]{0.72,0.33,0.31}{\times b}\textcolor[rgb]{0.72,0.33,0.31}{_{i}}}\\
    +\\
    \vdots \\
    +\\
    A\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{_{\textcolor[rgb]{0,0,0}{m,} k}}} \times b_{m}
    \end{array} =a_{\textcolor[rgb]{0.29,0.56,0.89}{\boldsymbol{k}}}^{T} b\end{equation}
        
    所以
    \begin{equation}
    \begin{aligned}
        \frac{\partial f}{\partial x_{k}}(x)
        &=2 a_{k}^{T} A x-2 a_{k}^{T} b\\
        &=2 a_{k}^{T}(A x-b)
    \end{aligned}
    \end{equation}

    所以函数 $ f(x) $ 的梯度
\begin{equation}
\begin{aligned}
    \nabla f(x)&=\left[\begin{array}{c}
    \dfrac{\partial f}{\partial x_{1}}(x) \\
    \vdots \\
    \dfrac{\partial f}{\partial x_{n}}(x)
    \end{array}\right]\\
    &=2\left[\begin{array}{c}
    a_{1}^{T}(A x-b) \\
    a_{2}^{T}(A x-b) \\
    \vdots \\
    a_{n}^{T}(A x-b)
    \end{array}\right] \\
    &= 2\left[a_{1}, a_{2}, \cdots, a_{n}\right]^{T}(A x-b) \\
    &=2 A^{T}(A x-b) 
\end{aligned}
\end{equation}

令梯度等于0
\begin{equation}\nabla f(x)=2\left(A^{T} A x-A^{T} b\right)=0 \Rightarrow A^{T} A x=A^{T} b\end{equation}

$A$的列向量无关时，则 $ \hat{x}=\left(A^{T} A\right)^{-1} A^{T} b $.

\end{proof}

\section{The Geometry of Least Squares: 投影与$A$列空间的关系}

\begin{FigureCenter}{Projection of $\boldsymbol{b}$ into the column space of ${A}$, $A$ is any matrice. Sourced from \cite{Strang1993IntroductionTL}}
    \input{tikz_images/projection-onto-the-column-space-of-A-strang.tex}
\end{FigureCenter}

\begin{FigureCenter}{Projecting onto the column space of $A$ is also projecting onto the column space of $Q$}
    \input{tikz_images/projection-onto-a-is-also-onto-q.tex}
\end{FigureCenter}

矩阵 $ {A} \in \mathfrak{R}^{m \times n} $ 的列 $ a_{1}, a_{2}, \ldots, a_{n} \in \mathfrak{R}^{m} $ 的最小二乘法问题
\begin{equation}
\hat{x}=\arg \underset{x}{\min}\|A x-b\|_{2}^{2} ,\|A x-b\|_{2}^{2}=\left\|\sum_{j=1}^{n} a_{j} x_{j}-b\right\|_{2}^{2}
\end{equation}

向量 $ b $ 在 $ \operatorname{range}(A) $ 上的投影是 $ A\left(A^{T} A\right)^{-1} A^{T} b $.

残差向量 $ \hat{r}=A \hat{x}-b $ 满足 $ A^{T} \hat{r}=A^{T}(A \hat{x}-b)=0 $.残差向量 $ \hat{r} $ 正交于 $ A $ 的每一列，因此正交于$ \operatorname{range}(A) $.




\begin{theorem}[投影与$A$列空间的关系]
    $ A \hat{x} \in \operatorname{range}(A) $是$A$的列空间中最接近$b$的向量。 
    
    $ \hat{r}=A \hat{x} -b$正交于$A$的列空间（值域空间） $ \operatorname{range}(A) $.
\end{theorem}

\section{正规方程}

\begin{theorem}[最小二乘法问题的正规方程]

    \begin{equation} \nabla f(x)=0, f(x)=\|A x-b\|_{2}^{2} \end{equation}
等价于
\begin{equation}
A^{T} A x=A^{T} b
\end{equation}
\end{theorem}

系数矩阵 $ A^{T} A $ 是 $ A $ 的Gram矩阵，最小二乘法问题所有的解都满足正规方程。

\begin{theorem}
    如果$A$的列线性无关，则

    $ A^{T} A $ 为非奇异矩阵，正规方程此时有唯一解。
\end{theorem}


\section{QR分解求解最小二乘法}

\begin{theorem}[QR分解求解最小二乘法]
    若 $ {A} \in \mathfrak{R}^{m \times n} $ 的列向量线性无关，则存在 $ {A}={QR} $ 分解， $ Q \in \mathfrak{R}^{m \times n} $ , $ R \in \mathfrak{R}^{{n} \times n} $ 
    
    最小二乘法问题的解
\begin{equation}
\begin{aligned}
\hat{x}&=\left(A^{T} A\right)^{-1} A^{T} b \\
&=\left((Q R)^{T}(Q R)\right)^{-1}(Q R)^{T} b \\
&=\left(R^{T} Q^{T} Q R\right)^{-1} R^{T} Q^{T} b \\
&=\left(R^{T} R\right)^{-1} R^{T} Q^{T} b \\
&=R^{-1} Q^{T} b
\end{aligned}
\end{equation}
\end{theorem}


\begin{example}
    \begin{equation}
A=\left[\begin{array}{cc}
3 & -6 \\
4 & -8 \\
0 & 1
\end{array}\right], \quad b=\left[\begin{array}{c}
-1 \\
7 \\
0
\end{array}\right]
\end{equation}
首先对$A$进行QR分解
\begin{equation}
Q=\left[\begin{array}{cc}
3 / 5 & 0 \\
4 / 5 & 0 \\
0 & 1
\end{array}\right], \quad R=\left[\begin{array}{cc}
5 & -10 \\
0 & 1
\end{array}\right]
\end{equation}

计算 $ d=Q^{T} b=(5,2) $

求解 $ R x=d $
\begin{equation}
\left[\begin{array}{cc}
5 & -10 \\
0 & 1
\end{array}\right]\left[\begin{array}{l}
x_{1} \\
x_{2}
\end{array}\right]=\left[\begin{array}{l}
5 \\
2
\end{array}\right]
\end{equation}

解得 $ x_{1}=5, x_{2}=2 $

\end{example}


\subsection{The Complexity of Solving Least Square Problem via QR Decomposition}
\label{complexity:least-square-using-qr}

算法复杂度：

\begin{itemize}
    \item 首先对$A$进行QR分解 $ A=Q R\left(2 m n^{2}\right. $ flops $ ) $
    \item 计算矩阵向量乘积 $ d=Q^{T} b(2 {mn} $ flops $ ) $
    \item 通过回代求解 $ R x=d\left(n^{2}\right. $ flops $ ) $
    \item 复杂度: $ 2 m n^{2} $ flops
\end{itemize}



\section{求解正规方程可能带来的严重误差}

直接求解正规方程组求解：
\begin{equation}
A^{T} A x=A^{T} b
\end{equation}

可能会造成严重的舍入误差。

\begin{example}
    一个列向量“几乎”线性相关的矩阵
\begin{equation}
A=\left[\begin{array}{cc}
1 & -1 \\
0 & 10^{-5} \\
0 & 0
\end{array}\right],  b=\left[\begin{array}{c}
0 \\
10^{-5} \\
1
\end{array}\right]
\end{equation}

将中间结果四舍五入到小数点后8位。

方法 1 ：通过Gram矩阵求解
\begin{equation}
A^{T} A=\left[\begin{array}{cc}
1 & -1 \\
-1 & 1+10^{-10}
\end{array}\right] \approx\left[\begin{array}{cc}
1 & -1 \\
-1 & 1
\end{array}\right], A^{T} b=\left[\begin{array}{c}
0 \\
10^{-10}
\end{array}\right] \Rightarrow x=\left[\begin{array}{c}
10^{-10} \\
10^{-10}
\end{array}\right]
\end{equation}
经过四舍五入之后，Gram矩阵为奇异矩阵。


方法 2 : 通过对 $A$进行QR分解
\begin{equation}
Q=\left[\begin{array}{ll}
1 & 0 \\
0 & 1 \\
0 & 0
\end{array}\right],  R=\left[\begin{array}{cc}
1 & -1 \\
0 & 10^{-5}
\end{array}\right]
\end{equation}

\begin{equation}\begin{aligned}
    &\hat{x}=\left(A^{T} A\right)^{-1} A^{T} b=R^{-1} Q^{T} b \\
    \Rightarrow& R x=Q^{T} b\\
    \Rightarrow& \left[\begin{array}{cc}1 & -1 \\ 0 & 10^{-5}\end{array}\right]\left[\begin{array}{l}x_{1} \\ x_{2}\end{array}\right]=\left[\begin{array}{l}0 \\ 10^{-5}\end{array}\right] \\
    \Rightarrow& x=\left[\begin{array}{l}1 \\ 1\end{array}\right]
\end{aligned}\end{equation}

\end{example}

方法2 比方法1更稳定，因为它避免构造Gram矩阵。



\section{梯度下降法}

给定 $ A \in \mathfrak{R}^{m \times n}, {b} \in \mathfrak{R}^{m}, x \in \mathfrak{R}^{n} $ 目标函数:
\begin{equation}
f(x)=\|A x-b\|_{2}^{2}=\sum_{i=1}^{m}\left(\sum_{j=1}^{n} A_{i j} x_{j}-b_{i}\right)^{2}
\end{equation}
为使目标函数最小， 可求最优解 $ \hat{x}: \quad \hat{x}=\arg \underset{x}{ \min } f(x) $.

\begin{problem}
    $ A \in \mathfrak{R}^{{m} \times n} $ 列向量线性相关或$n$非常大，$
    A^{T} A \in \mathfrak{R}^{n \times n}$不可逆，无法直接代入求得最小二乘解。
\end{problem}

通过迭代求解目标的最优解过程: \begin{equation} x^{(1)}, x^{(2)}, \cdots, x^{(k)} \rightarrow \hat{x} \end{equation} 

设 $ x^{(k)} $ 是第$k$步迭代，期望更新 $ x^{(k+1)} $ ,满足 $ f\left(x^{(k+1)}\right)<f\left(x^{(k)}\right) $.

设函数 $ f(x) $ 可微，根据泰勒公式，在 $ x^{(k)} $ 的一阶公式为
\begin{equation}
f\left(x^{(k+1)}\right)=f\left(x^{(k)}\right)+\left\langle\nabla f\left(x^{(k)}\right), x^{(k+1)}-x^{(k)}\right\rangle+o\left(\left\|x^{(k+1)}-x^{(k)}\right\|\right)
\end{equation}

如果 $ \left\|x^{(k+1)}-x^{(k)}\right\|_{2} $ 足够小， 则有
\begin{equation}
f\left(x^{(k+1)}\right)-f\left(x^{(k)}\right) \approx\left\langle\nabla f\left(x^{(k)}\right), x^{(k+1)}-x^{(k)}\right\rangle
\end{equation}

\begin{corollary}
    根据Cauchy-Schwarz不等式 \ref{thm:cauchy-schwartz=inequality}

    $ \left|\left\langle\nabla f\left(x^{(k)}\right), x^{(k+1)}-x^{(k)}\right\rangle\right| \leq\left\|\nabla f\left(x^{(k)}\right)\right\|_{2}\left\|x^{(k+1)}-x^{(k)}\right\|_{2} $

    所以有
    \begin{equation}
\left\langle\nabla f\left(x^{(k)}\right), x^{(k+1)}-x^{(k)}\right\rangle \geq -\left\|\nabla f\left(x^{(k)}\right)\right\|_{2}\left\|x^{(k+1)}-x^{(k)}\right\|_{2}
\end{equation}

当 $ x^{(k+1)}-x^{(k)}=-\alpha_{k} \nabla f\left(x^{(k)}\right), \alpha_{k}>0 $ 时，等式成立。

由于$-\left\|\nabla f\left(x^{(k)}\right)\right\|_{2}\left\|x^{(k+1)}-x^{(k)}\right\|_{2}$是非负的，此时$f\left(x^{(k+1)}\right)-f\left(x^{(k)}\right) \le 0$.
\end{corollary}

迭代公式为 

\begin{equation}  x^{(k+1)}=x^{(k)}-\alpha_{k} \nabla f\left(x^{(k)}\right) , f\left(x^{(k+1)}\right)<f\left(x^{(k)}\right) \end{equation}


\begin{definition}[梯度下降法求解最小二乘法]
    \begin{equation}
\min _{x \in \mathfrak{R}^{n}} \frac{1}{2}\|A x-b\|_{2}^{2}, \quad A \in \mathfrak{R}^{m \times n}, b \in \mathfrak{R}^{m}
\end{equation}

令 \begin{equation} f(x)=\frac{1}{2}\|A x-b\|_{2}^{2} \end{equation}

则 $ f $ 为凸函数， 并有 $ \nabla f(x)=A^{T}(A x-b) $.

则 $ A^{T} A \in \mathfrak{R}^{n \times n} $ .如果列向量\textbf{线性相关}会导致其\textbf{不可逆}或$n$非常大。可以通过梯度下降法迭代

\begin{equation}  x^{(k+1)}=x^{(k)}-\alpha_{k} \nabla f\left(x^{(k)}\right) , f\left(x^{(k+1)}\right)<f\left(x^{(k)}\right) \end{equation}

求解

\begin{equation} x^{(k+1)}=x^{(k)}-\alpha^{(k)} A^{T}\left(A x^{(k)}-b\right) \end{equation}
\end{definition}


\begin{algorithm}[htbp]
    \caption{梯度下降法}
    初始化 $ x^{(0)} $, $k=0$\;
    \While(){Not Convergent}{
        $p^{(k)}=A^{T}\left(A x^{(k)}-b\right)$\;
        $x^{(k+1)}=x^{(k)}-\alpha^{(k)} p^{(k)}$\;
        $k \leftarrow k + 1$
    }
\end{algorithm}

\section{估计学习率（步长）$\alpha$}

\begin{problem}
    \begin{equation}
    \min _{x \in \mathfrak{R}^{n}} \frac{1}{2}\|A x-b\|_{2}^{2}, \quad A \in \mathfrak{R}^{m \times n}, b \in \mathfrak{R}^{m}
    \end{equation}
    
    令 $ f(x)=\frac{1}{2}\|A x-b\|_{2}^{2} $

    \begin{equation} x^{(k+1)}=x^{(k)}-\alpha^{(k)} A^{T}\left(A x^{(k)}-b\right) \end{equation}

    需要估计 $ \alpha^{(k)} $.
\end{problem}

为了估计 $ \alpha^{(k)} $, 通过线性搜索估计:
\begin{equation}
\alpha^{(k)}=\arg \min _{\alpha \in \Re} f\left(x^{(k)}-\alpha A^{T}\left(A x^{(k)}-b\right)\right)
\end{equation}

即 $ \alpha^{(k)} $ 是最优步长。在上面的优化式中$x^{(k)}$、$A$、$b$均视为定值。

\begin{theorem}[线性搜索估计的最优步长]
    \begin{equation}\alpha^{(k)}=\frac{\left\|A^{T}\left(A x^{(k)}-b\right)\right\|_{2}^{2}}{\left\|A A^{T}\left(A x^{(k)}-b\right)\right\|_{2}^{2}}\end{equation}
\end{theorem}

\begin{proof}
    令 $ g(\alpha)=f\left(x^{(k)}-\alpha A^{T}\left(A x^{(k)}-b\right)\right) $ 是关于 $ \alpha $ 的 凸函数， 则有

\begin{equation}
\min _{\alpha} g(\alpha) \Rightarrow g^{\prime}(\alpha)=0 \Rightarrow \alpha^{(k)}=\frac{\left\|A^{T}\left(A x^{(k)}-b\right)\right\|_{2}^{2}}{\left\|A A^{T}\left(A x^{(k)}-b\right)\right\|_{2}^{2}}
\end{equation}


\begin{equation}\begin{aligned}
    & f(x)=\frac{1}{2}\|A x-b\|_{2}^{2}, g\left(\alpha^{(k)}\right)=f\left({\color{violet} x^{(k)}-\alpha^{(k)} A^{T}\left(A x^{(k)}-b\right)} \right) \\
    \Rightarrow & g\left(\alpha^{(k)}\right)=\frac{1}{2}\left\|A\left({\color{violet} x^{(k)}-\alpha^{(k)} A^{T}\left(A x^{(k)}-b\right)} \right)-b\right\|_{2}^{2} \\
    &=\frac{1}{2}\left\|\left({\color{coral} A x^{(k)}-b} \right)-\left({\color{grass} \alpha^{(k)} A^{T}\left(A x^{(k)}-b\right)} \right)\right\|_{2}^{2} \\
    &=\frac{1}{2}\left(\left({\color{coral} A x^{(k)}-b} \right)^{T}\left({\color{coral} A x^{(k)}-b} \right)+\left({\color{grass} \alpha^{(k)} A^{T}\left(A x^{(k)}-b\right)} \right)^{T}\left({\color{grass} \alpha^{(k)} A^{T}\left(A x^{(k)}-b\right)} \right)\right) \\
    &-\left({\color{coral} A x^{(k)}-b} \right)^{T}\left({\color{grass} \alpha^{(k)} A^{T}\left(A x^{(k)}-b\right)} \right) \\
    \Rightarrow & g^{\prime}\left(\alpha^{(k)}\right)=\alpha^{(k)}\left(A^{T}\left(A x^{(k)}-b\right)\right)^{T}\left(A^{T}\left(A x^{(k)}-b\right)\right)-\left(A x^{(k)}-b\right)^{T}\left(A^{T}\left(A x^{(k)}-b\right)\right)=0 \\
    \Rightarrow &\alpha^{(k)}=\frac{\left\|A^{T}\left(A x^{(k)}-b\right)\right\|_{2}^{2}}{\left\|A A^{T}\left(A x^{(k)}-b\right)\right\|_{2}^{2}}
    \end{aligned}\end{equation}

\end{proof}


\begin{algorithm}[htbp]
    \caption{使用线性搜索估计步长的梯度下降法}
    初始化 $ x^{(0)} $, $k=0$\;
    \While(){Not Convergent}{
        $p^{(k)}=A^{T}\left(A x^{(k)}-b\right)$\;
        $\alpha^{(k)}=\dfrac{\left\|p^{(k)}\right\|_{2}^{2}}{\left\|A p^{(k)}\right\|_{2}^{2}}$\;
        $x^{(k+1)}=x^{(k)}-\alpha^{(k)} p^{(k)}$\;
    }
\end{algorithm}